<!DOCTYPE html>
<html lang="en" >

<!-- Head -->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" >    <!-- Metadata, OpenGraph and Schema.org -->

<!-- Standard metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Maria  Teleki</title>
<meta name="author" content="Maria  Teleki">
<meta name="description" content="Personal website for Maria Teleki.">
<meta name="keywords" content="natural-language-processing, portfoilio-website, maria-teleki, researcher, computer-science">

<!-- Fonts & Icons -->
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> -->
<link rel="stylesheet" href="./assets/fontawesome-free-5.15.4-web/css/all.min.css"/>  
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> -->
<link rel="stylesheet" href="./assets/academicons-1.9.4/css/academicons.min.css"/> 
<!-- <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> -->
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Bootstrap & MDB -->
<!-- <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> -->
<link href="./assets/bootstrap-4.6.1-dist/css/bootstrap.min.css" rel="stylesheet">
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> -->
<link href="./assets/MDB-Free_4.20.0/css/mdb.min.css" rel="stylesheet">

<!-- Local Stylesheet -->
<link rel="stylesheet" href="./main.css">

</head>

<!-- Body -->
<body class="fixed-top-nav">

<!-- Header -->
<header>

<!-- Nav Bar -->
<nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top bg-white z-depth-0">
<div class="container">
  <div class="navbar-brand social">
    <!--<a href="mailto:mariateleki@tamu.edu" title="Email"><i class="fa fa-envelope"></i></a> -->
    <a href="https://www.linkedin.com/in/mariateleki" title="LinkedIn" rel="external nofollow noopener noopener noreferrer" target="_blank"><i class="fab fa-xs fa-linkedin"></i></a>
    <a href="https://dblp.org/pid/359/3074.html" title="DBLP" rel="external nofollow noopener noopener noreferrer" target="_blank"><i class="ai ai-xs ai-dblp"></i></a>
    <a href="https://scholar.google.com/citations?hl=en&user=aImLrNcAAAAJ" title="Google Scholar" rel="external nofollow noopener noopener noreferrer" target="_blank"><i class="ai ai-xs ai-google-scholar"></i></a>
    <a href="https://github.com/mariateleki" title="GitHub" rel="external nofollow noopener noopener noreferrer" target="_blank"><i class="fab fa-xs fa-github"></i></a>
    <a href="./pdf/Maria_Teleki_CV.pdf" title="CV" rel="external nofollow noopener noopener noreferrer" target="_blank"><i class="ai ai-xs ai-cv-square"></i></a>
    <a href="https://www.youtube.com/@MariaTelekiCS" title="YouTube" rel="external nofollow noopener noopener noreferrer" target="_blank"><i class="fab fa-xs fa-youtube"></i></a>
    <a href="https://medium.com/@mariatelekiresearch" title="Medium" rel="external nofollow noopener noopener noreferrer" target="_blank"><i class="fab fa-xs fa-medium-m"></i></a>
    <!-- <a href="https://orcid.org/0009-0006-7015-4015" title="ORCiD" rel="external nofollow noopener noopener noreferrer" target="_blank"><i class="ai ai-xs ai-orcid"></i></a> -->
    <!-- ACL Anthology https://aclanthology.org/people/m/maria-teleki/-->
    <!-- Open Review https://openreview.net/profile?id=~Maria_Teleki1 -->
    <!-- <a href="." title="arXiv" rel="external nofollow noopener noopener noreferrer" target="_blank"><i class="ai ai-xs ai-arxiv"></i></a> -->
    <!-- <a href="." title="Spotify" rel="external nofollow noopener noopener noreferrer" target="_blank"><i class="fab fa-spotify"></i></a> -->
    
  </div>

  <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="sr-only">Toggle navigation</span>
    <span class="icon-bar top-bar"></span>
    <span class="icon-bar middle-bar"></span>
    <span class="icon-bar bottom-bar"></span>
  </button>

  <div class="collapse navbar-collapse text-right" id="navbarNav">
    <ul class="navbar-nav ml-auto flex-nowrap">
      <li class="nav-item"><a class="nav-link" href="#top">About</a></li>
      <li class="nav-item"><a class="nav-link" href="#news_id">News</a></li>
      <li class="nav-item"><a class="nav-link" href="#publications_id">Publications</a></li>
      <li class="nav-item"><a class="nav-link" href="#education_id">Education</a></li>
      <li class="nav-item"><a class="nav-link" href="#service_id">Service</a></li>
      <li class="nav-item"><a class="nav-link" href="#work_id">Work</a></li>
      <li class="nav-item"><a class="nav-link" href="#teaching_id">Teaching</a></li>
      <li class="nav-item"><a class="nav-link" href="#more_id">More</a></li>
    </ul>
  </div>
</div>
</nav>


</header>

<!-- Content -->
<div class="container mt-5">
<!-- about.html -->
<div class="post">
<header class="post-header">
  <h1 class="post-title"><span class="font-weight-bold">Maria</span>  Teleki</h1>
  <p class="desc">PhD Student in <a href="https://engineering.tamu.edu/cse/index.html" rel="external nofollow noopener noopener noreferrer" target="_blank">Computer Science</a> at <a href="https://www.tamu.edu/" rel="external nofollow noopener noopener noreferrer" target="_blank">Texas A&amp;M University</a>.</p>
</header>

<article>

<div class="profile float-left"><img src="./img/me.jpg" class="img-fluid rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  <div class="more-info">
    <!--<i>
    <a href="https://lrec-coling-2024.org/">LREC-COLING 2024</a>
    </i>-->
  </div>
</div>
<div class="clearfix">
  <p style="font-size: medium;">Howdy! I’m a third-year PhD Student in <a href="https://engineering.tamu.edu/cse/index.html" rel="external nofollow noopener noopener noreferrer" target="_blank">Computer Science</a> at <a href="https://www.tamu.edu/" rel="external nofollow noopener noopener noreferrer" target="_blank">Texas A&amp;M University</a>  (gig em! <img class="emoji" title=":+1:" alt=":+1:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png" height="20" width="20">) in InfoLab, advised by <a href="https://people.engr.tamu.edu/caverlee" rel="external nofollow noopener noopener noreferrer" target="_blank">Prof. James Caverlee</a>. 
    Previously, I graduated from Texas A&M University with a B.S. in Computer Science and a minor in Mathematics. </p>
    <!-- I am supported by a Dr. Dionel Avilés ’53 and Dr. James Johnson ’67 Fellowship in Computer Science and Engineering. </p >-->
  <p style="font-size: medium;">My work focuses on disfluency in spoken content -- <i>How do disfluencies impact LLM task performance? How does the choice of ASR system impact a model’s ability to identify disfluencies?</i> I also work on algorithms that identify and mitigate gender bias in language models. <b><i>Keywords: Disfluency, Large Language Models, Gender Bias</i></b></p>
  <p style="font-size: medium;">The best way to contact me is through email: <code class="language-plaintext highlighter-rouge">mariateleki@tamu.edu</code>. Please reach out if you have any questions or want to know more about our work!</p>
</div>
    


<div class="news">
<h2 id="news_id">News</h2>
<div class="table-responsive" style="height:100px; overflow-y:scroll;">
<table class="table table-sm table-borderless">
  <tr>
    <th scope="row">Oct 7, 2024</th>
    <td>Gave a talk at the <a href="https://vbma.biz">Texas Tech University - School of Veterinary Medicine VBMA Club</a>! Check it out here: <i><a href="./pdf/The Other AI.pdf">The Other AI: An Intuitive Understanding of Artificial Intelligence</a></i>. <img alt=":txtech:" src="./img/txtech.png" height="20" width="20"> </td>
  </tr>
<tr>
  <th scope="row" style="width: 120px;">June 4, 2024</th>
  <td>Our work was accepted to INTERSPEECH!<img alt=":interspeech2024:" src="./img/interspeech24.png" height="20" width="20"></td>
</tr> 
<tr>
  <th scope="row" style="width: 120px;">April 19, 2024</th>
  <td>Had a great time meeting and learning from so many awesome people at the <a href="https://cra.org/cra-wp/grad-cohort-for-women/">CRA-WP Grad Cohort for Women</a> in Minneapolis, MN! <img alt=":CRA-WP:" src="./img/CRA-WP.png" height="20" width="20"></td>
</tr> 
<tr>
  <th scope="row">Mar 14, 2024</th>
  <td>We had 2 papers accepted to LREC-COLING on disfluency and language modeling! <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"></td>
</tr> 
</table>
</div> 
</div>


<h2 id="publications_id">Publications</h2>
<div class="table-responsive-sm">
<table class="table table-borderless table-sm"> 

<!-- Comparing ASR Paper-->
<tr>
<td style="width: 35%; vertical-align: top;">
  <img class="preview rounded z-depth-0" width="95%" src="./img/interspeech_diagram.png">
</td>

<td style="font-size: large;">Comparing ASR Systems in the Context of Speech Disfluencies<br>
  <b style="font-size: medium;"><b><u>Maria Teleki</u></b>, Xiangjue Dong, Soohwan Kim, and James Caverlee</div></b><br>
  <a href="https://interspeech2024.org/">INTERSPEECH 2024<br></a>
  <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="https://www.isca-archive.org/interspeech_2024/teleki24_interspeech.pdf" role="button">Paper</a>
  <button class="btn btn-light btn-sm z-depth-0 text-dark" type="button" data-toggle="collapse" data-target="#abstract-text-5" aria-expanded="false" aria-controls="collapseExample">Abstract</button>
  <button class="btn btn-light btn-sm z-depth-0 text-dark" type="button" data-toggle="collapse" data-target="#bib-text-5" aria-expanded="false" aria-controls="collapseExample">Bib</button>
  <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="https://github.com/mariateleki/Comparing-ASR-Systems" role="button">Code</a>
  <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="https://www.comparing-asr-systems.com" role="button">Project Website</a>
  <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="./pdf/Resized-Interspeech-2024-Poster.pdf" role="button">Poster</a> 
  <!-- <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="." role="button">Video</a>  -->
  <!-- <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="." role="button">Video Transcript</a> -->
  <!-- <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="." role="button">Slides</a> -->
  <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="https://www.isca-archive.org/interspeech_2024/teleki24_interspeech.html" role="button">ISCA Archive Link</a>

  <div class="collapse" id="abstract-text-5">
    <div class="card card-body z-depth-0" style="font-size: small;">
      In this work, we evaluate the disfluency capabilities of two automatic speech recognition systems -- Google ASR and WhisperX -- through a study of 10 human-annotated podcast episodes and a larger set of 82,601 podcast episodes. We employ a state-of-the-art disfluency annotation model to perform a fine-grained analysis of the disfluencies in both the scripted and non-scripted podcasts. We find, on the set of 10 podcasts, that while WhisperX overall tends to perform better, Google ASR outperforms in WIL and BLEU scores for non-scripted podcasts. We also find that Google ASR's transcripts tend to contain closer to the ground truth number of edited-type disfluent nodes, while WhisperX's transcripts are closer for interjection-type disfluent nodes. This same pattern is present in the larger set. Our findings have implications for the choice of an ASR model when building a larger system, as the choice should be made depending on the distribution of disfluent nodes present in the data.
    </div>
  </div>

  <div class="collapse" id="bib-text-5">
    <div class="card card-body z-depth-0">
      <code class="language-plaintext highlighter-rouge" style="font-size: small;">
        @inproceedings{teleki24_interspeech,<br>
          title     = {Comparing ASR Systems in the Context of Speech Disfluencies},<br>
          author    = {Maria Teleki and Xiangjue Dong and Soohwan Kim and James Caverlee},<br>
          year      = {2024},<br>
          booktitle = {Interspeech 2024},<br>
          pages     = {4548--4552},<br>
          doi       = {10.21437/Interspeech.2024-1270},<br>
        }
      </code>
    </div>
  </div>
</td>
</tr>
<!-- End Comparing ASR Paper-->

<!-- Quantifying Paper-->
<tr>
  <td style="width: 35%; vertical-align: top;">
    <img class="preview rounded z-depth-0" width="95%" src="./img/Quantifying.png">
  </td>
  
  <td style="font-size: large;">Quantifying the Impact of Disfluency on Spoken Content Summarization<br>
    <b style="font-size: medium;"><b><u>Maria Teleki</u></b>, Xiangjue Dong, and James Caverlee</div></b><br>
    <a href="https://lrec-coling-2024.org/">LREC-COLING 2024<br></a>
    <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="https://aclanthology.org/2024.lrec-main.1175.pdf" role="button">Paper</a> 
    <button class="btn btn-light btn-sm z-depth-0 text-dark" type="button" data-toggle="collapse" data-target="#abstract-text-4" aria-expanded="false" aria-controls="collapseExample">Abstract</button>
    <button class="btn btn-light btn-sm z-depth-0 text-dark" type="button" data-toggle="collapse" data-target="#bib-text-4" aria-expanded="false" aria-controls="collapseExample">Bib</button>
    <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="https://github.com/mariateleki/Quantifying-Impact-Disfluency" role="button">Code</a> 
    <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="./pdf/Quantifying LREC-COLING Poster.pdf" role="button">Poster</a> 
    <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="https://www.youtube.com/watch?v=iTlJiEHN5Rk" role="button">Video</a> 
    <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="./pdf/Quantifying LREC-COLING Slides.pdf" role="button">Slides</a> 
    <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="https://aclanthology.org/2024.lrec-main.1175/" role="button">ACL Anthology Link</a>

    <div class="collapse" id="abstract-text-4">
      <div class="card card-body z-depth-0" style="font-size: small;">
        Spoken content is abundant -- including podcasts, meeting transcripts, and TikTok-like short videos. And yet, many important tasks like summarization are often designed for written content rather than the looser, noiser, and more disfluent style of spoken content. Hence, we aim in this paper to quantify the impact of disfluency on spoken content summarization. Do disfluencies negatively impact the quality of summaries generated by existing approaches? And if so, to what degree? Coupled with these goals, we also investigate two methods towards improving summarization in the presence of such disfluencies. We find that summarization quality does degrade with an increase in these disfluencies and that a combination of multiple disfluency types leads to even greater degradation. Further, our experimental results show that naively removing disfluencies and augmenting with special tags can worsen the summarization when used for testing, but that removing disfluencies for fine-tuning yields the best results. We make the code available at https://github.com/mariateleki/Quantifying-Impact-Disfluency.
      </div>
    </div>
  
    <div class="collapse" id="bib-text-4">
      <div class="card card-body z-depth-0">
        <code class="language-plaintext highlighter-rouge" style="font-size: small;">
          @inproceedings{teleki-etal-2024-quantifying-impact,<br>
            title = "Quantifying the Impact of Disfluency on Spoken Content Summarization",<br>
            author = "Teleki, Maria  and<br>
              Dong, Xiangjue  and<br>
              Caverlee, James",<br>
            editor = "Calzolari, Nicoletta  and<br>
              Kan, Min-Yen  and<br>
              Hoste, Veronique  and<br>
              Lenci, Alessandro  and<br>
              Sakti, Sakriani  and<br>
              Xue, Nianwen",<br>
            booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",<br>
            month = may,<br>
            year = "2024",<br>
            address = "Torino, Italia",<br>
            publisher = "ELRA and ICCL",<br>
            url = "https://aclanthology.org/2024.lrec-main.1175",<br>
            pages = "13419--13428",<br>
            abstract = "Spoken content is abundant {--} including podcasts, meeting transcripts, and TikTok-like short videos. And yet, many important tasks like summarization are often designed for written content rather than the looser, noiser, and more disfluent style of spoken content. Hence, we aim in this paper to quantify the impact of disfluency on spoken content summarization. Do disfluencies negatively impact the quality of summaries generated by existing approaches? And if so, to what degree? Coupled with these goals, we also investigate two methods towards improving summarization in the presence of such disfluencies. We find that summarization quality does degrade with an increase in these disfluencies and that a combination of multiple disfluency types leads to even greater degradation. Further, our experimental results show that naively removing disfluencies and augmenting with special tags can worsen the summarization when used for testing, but that removing disfluencies for fine-tuning yields the best results. We make the code available at https://github.com/mariateleki/Quantifying-Impact-Disfluency.",<br>
        }        
        </code>
      </div>
    </div>

  </td>
  </tr>
<!-- End Quantifying Paper-->

<!-- DACL Paper-->
<tr>
  <td style="width: 35%; vertical-align: top;">
    <img class="preview rounded z-depth-0" width="95%" src="./img/DACL.png"></div>
  </td>
  
  <td style="font-size: large;">DACL: Disfluency Augmented Curriculum Learning for Fluent Text Generation<br>
    <b style="font-size: medium;">Rohan Chaudhury, <b><u>Maria Teleki</u></b>, Xiangjue Dong, and James Caverlee</div></b><br>
    <a href="https://lrec-coling-2024.org/">LREC-COLING 2024<br></a>
    <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="https://aclanthology.org/2024.lrec-main.385.pdf" role="button">Paper</a> 
    <button class="btn btn-light btn-sm z-depth-0 text-dark" type="button" data-toggle="collapse" data-target="#abstract-text-3" aria-expanded="false" aria-controls="collapseExample">Abstract</button>
    <button class="btn btn-light btn-sm z-depth-0 text-dark" type="button" data-toggle="collapse" data-target="#bib-text-3" aria-expanded="false" aria-controls="collapseExample">Bib</button>
    <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="https://github.com/Rohan-Chaudhury/Generating-Fluent-Text-through-Curriculum-Learning-And-Disfluency-Augmentation" role="button">Code</a> 
    <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="./pdf/DACL LREC-COLING Poster.pdf" role="button">Poster</a> 
    <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="https://youtu.be/8VIDlocdaco?si=35wXmBLOMNbrYz1X" role="button">Video</a>
    <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="./pdf/DACL Presentation.pdf" role="button">Slides</a>
    <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="https://aclanthology.org/2024.lrec-main.385/" role="button">ACL Anthology Link</a>
  
    <div class="collapse" id="abstract-text-3">
      <div class="card card-body z-depth-0" style="font-size: small;">
        Voice-driven software systems are in abundance. However, language models that power these systems are traditionally trained on fluent, written text corpora. Hence there can be a misalignment between the inherent disfluency of transcribed spoken content and the fluency of the written training data. Furthermore, gold-standard disfluency annotations of various complexities for incremental training can be expensive to collect. So, we propose in this paper a Disfluency Augmented Curriculum Learning (DACL) approach to tackle the complex structure of disfluent sentences and generate fluent texts from them, by using Curriculum Learning (CL) coupled with our synthetically augmented disfluent texts of various levels. DACL harnesses the tiered structure of our generated synthetic disfluent data using CL, by training the model on basic samples (i.e. more fluent) first before training it on more complex samples (i.e. more disfluent). In contrast to the random data exposure paradigm, DACL focuses on a simple-to-complex learning process. We comprehensively evaluate DACL on Switchboard Penn Treebank-3 and compare it to the state-of-the-art disfluency removal models. Our model surpasses existing techniques in word-based precision (by up to 1%) and has shown favorable recall and F1 scores.
      </div>
    </div>
  
    <div class="collapse" id="bib-text-3">
      <div class="card card-body z-depth-0">
        <code class="language-plaintext highlighter-rouge" style="font-size: small;">
          @inproceedings{chaudhury-etal-2024-dacl-disfluency,<br>
            title = "{DACL}: Disfluency Augmented Curriculum Learning for Fluent Text Generation",<br>
            author = "Chaudhury, Rohan  and<br>
              Teleki, Maria  and<br>
              Dong, Xiangjue  and<br>
              Caverlee, James",<br>
            editor = "Calzolari, Nicoletta  and<br>
              Kan, Min-Yen  and<br>
              Hoste, Veronique  and<br>
              Lenci, Alessandro  and<br>
              Sakti, Sakriani  and<br>
              Xue, Nianwen",<br>
            booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",<br>
            month = may,<br>
            year = "2024",<br>
            address = "Torino, Italia",<br>
            publisher = "ELRA and ICCL",<br>
            url = "https://aclanthology.org/2024.lrec-main.385",<br>
            pages = "4311--4321",<br>
            abstract = "Voice-driven software systems are in abundance. However, language models that power these systems are traditionally trained on fluent, written text corpora. Hence there can be a misalignment between the inherent disfluency of transcribed spoken content and the fluency of the written training data. Furthermore, gold-standard disfluency annotations of various complexities for incremental training can be expensive to collect. So, we propose in this paper a Disfluency Augmented Curriculum Learning (DACL) approach to tackle the complex structure of disfluent sentences and generate fluent texts from them, by using Curriculum Learning (CL) coupled with our synthetically augmented disfluent texts of various levels. DACL harnesses the tiered structure of our generated synthetic disfluent data using CL, by training the model on basic samples (i.e. more fluent) first before training it on more complex samples (i.e. more disfluent). In contrast to the random data exposure paradigm, DACL focuses on a simple-to-complex learning process. We comprehensively evaluate DACL on Switchboard Penn Treebank-3 and compare it to the state-of-the-art disfluency removal models. Our model surpasses existing techniques in word-based precision (by up to 1{\%}) and has shown favorable recall and F1 scores.",<br>
        }        
        </code>
      </div>
    </div>
  </td>
  </tr>
  <!-- End DACL Paper-->

<!-- Co2PT Paper-->
<tr>
<td style="width: 35%; vertical-align: top;">
  <img class="preview rounded z-depth-0" width="95%" src="./img/diagram3.png"></div>
</td>

<td style="font-size: large;">Co2PT: Mitigating Bias in Pre-trained Language Models through Counterfactual Contrastive Prompt Tuning<br>
  <b style="font-size: medium;">Xiangjue Dong, Ziwei Zhu, Zhuoer Wang, <b><u>Maria Teleki</u></b>, and James Caverlee</div></b><br>
  <a href="https://2023.emnlp.org/program/">Findings of EMNLP 2023<br></a>
  <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="./pdf/co2pt-paper.pdf" role="button">Paper</a>
  <button class="btn btn-light btn-sm z-depth-0 text-dark" type="button" data-toggle="collapse" data-target="#abstract-text-2" aria-expanded="false" aria-controls="collapseExample">Abstract</button>
  <button class="btn btn-light btn-sm z-depth-0 text-dark" type="button" data-toggle="collapse" data-target="#bib-text-2" aria-expanded="false" aria-controls="collapseExample">Bib</button>
  <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="https://github.com/dongxiangjue/Co2PT" role="button">Code</a>
  <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="https://aclanthology.org/2023.findings-emnlp.390/" role="button">ACL Anthology Link</a>

  <div class="collapse" id="abstract-text-2">
    <div class="card card-body z-depth-0" style="font-size: small;">
      Pre-trained Language Models are widely used in many important real-world applications. However, recent studies show that these models can encode social biases from large pre-training corpora and even amplify biases in downstream applications. To address this challenge, we propose Co2PT, an efficient and effective debias-while-prompt tuning method for mitigating biases via counterfactual contrastive prompt tuning on downstream tasks. Our experiments conducted on three extrinsic bias benchmarks demonstrate the effectiveness of Co2PT on bias mitigation during the prompt tuning process and its adaptability to existing upstream debiased language models. These findings indicate the strength of Co2PT and provide promising avenues for further enhancement in bias mitigation on downstream tasks.
    </div>
  </div>

  <div class="collapse" id="bib-text-2">
    <div class="card card-body z-depth-0">
      <code class="language-plaintext highlighter-rouge" style="font-size: small;">
          @article{DBLP:journals/corr/abs-2310-12490,<br>
            author = {Dong, Xiangjue and Zhu, Ziwei and Wang, Zhuoer and Teleki, Maria and Caverlee, James},<br>
            title = {Co2PT: Mitigating Bias in Pre-trained Language Models through Counterfactual Contrastive Prompt Tuning},<br>
            journal = {Findings of EMNLP},<br>
            year = {2023},<br>
            url = {https://doi.org/10.48550/arXiv.2310.12490},<br>
          }
      </code>
    </div>
  </div>
</td>
</tr>
<!-- End Co2PT Paper-->

<!-- Alexa Prize Paper-->
<tr>
  <td style="width: 35%; vertical-align: top;">
    <img class="preview rounded z-depth-0" width="95%" src="./img/taskbot.png"></div>
  </td>
  
  <td style="font-size: large;">Howdy Y’all: An Alexa TaskBot<br>
    <b style="font-size: medium;">Majid Alfifi, Xiangjue Dong, Timo Feldman, Allen Lin, Karthic Madanagopal, Aditya Pethe, <b><u>Maria Teleki</u></b>, Zhuoer Wang, Ziwei Zhu, James Caverlee</div></b><br>
    <a href="https://www.amazon.science/alexa-prize/proceedings/howdy-yall-an-alexa-taskbot">Alexa Prize TaskBot Challenge Proceedings 2022<br></a>
    <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="./pdf/howdy-yall-paper.pdf" role="button">Paper</a>
    <button class="btn btn-light btn-sm z-depth-0 text-dark" type="button" data-toggle="collapse" data-target="#abstract-text-1" aria-expanded="false" aria-controls="collapseExample">Abstract</button>
    <button class="btn btn-light btn-sm z-depth-0 text-dark" type="button" data-toggle="collapse" data-target="#bib-text-1" aria-expanded="false" aria-controls="collapseExample">Bib</button>
    <a class="btn btn-light btn-sm z-depth-0 text-dark" style="text-decoration: none;" href="https://www.amazon.science/academic-engagements/ten-university-teams-selected-to-participate-in-alexa-prize-taskbot-challenge" role="button">Amazon Science Link</a>

    <div class="collapse" id="abstract-text-1">
      <div class="card card-body z-depth-0" style="font-size: small;">
        In this paper, we present Howdy Y’all, a multi-modal task-oriented dialogue agent developed for the 2021-2022 Alexa Prize TaskBot competition. Our design principles guiding Howdy Y’all aim for high user satisfaction through friendly and trustworthy encounters, minimization of negative conversation edge cases, and wide coverage over many tasks. Hence, Howdy Y’all is built upon a rapid prototyping platform to enable fast experimentation and powered by four key innovations to enable this vision: (i) First, it combines a rules, phonetic matching, and a transformer-based approach for robust intent understanding. (ii) Second, to accurately elicit user preferences and guide users to the right task, Howdy Y’all is powered by a contrastive learning search framework over sentence embeddings and a conversational recommender for eliciting preferences. (iii) Third, to support a variety of user question types, it introduces a new data augmentation method for question generation and a self-supervised answer selection approach for improving question answering. (iv) Finally, to help motivate our users and keep them engaged, we design an emotional conversation tracker that provides empathetic responses to keep users engaged and a monitor of conversation quality.
      </div>
    </div>
  
    <div class="collapse" id="bib-text-1">
      <div class="card card-body z-depth-0">
        <code class="language-plaintext highlighter-rouge" style="font-size: small;">
          @inproceedings{University2022,<br>
            author={Alfifi, Majid and Dong, Xiangjue and Feldman, Timo and Lin, Allen and Madanagopal, Karthic and Pethe, Aditya and Teleki, Maria and Wang, Zhuoer and Zhu, Ziwei and Caverlee, James},<br>
            title = {Howdy Y’all: An Alexa TaskBot},<br>
            year = {2022},<br>
            url = {https://www.amazon.science/alexa-prize/proceedings/howdy-yall-an-alexa-taskbot},<br>
            booktitle = {Alexa Prize TaskBot Challenge Proceedings},<br>
          }
        </code>
      </div>
    </div>
  </td>
  </tr>
  <!-- Alexa Prize Paper-->

</table>
</div>


<div class="education">
<h2 id="education_id">Education</h2>
<div class="table-responsive-sm">
<table class="table table-borderless table-sm"> 
  <tr>
    <td style="width: 35%; vertical-align: top;">
        <b style="font-size: large;">Texas A&amp;M University</b><br>
        <b style="font-size: large;">Ph.D. Computer Science</b><br>
        College Station, TX<br>
        2022-Present
    </td>
    <td style="white-space: pre-wrap; vertical-align: top; font-size: medium;">(2022-2026) <b>Dr. Dionel Avilés ’53 and Dr. James Johnson ’67 Fellowship in Computer Science and Engineering</b><br>(Spring 2024) <b><a href="https://cra.org/cra-wp/grad-cohort-for-women/">CRA-WP Grad Cohort for Women</a></b><br>(Spring 2024) Department Travel Grant</td>
  </tr>  

  <tr>
        <td style="width: 35%; vertical-align: top;">
            <b style="font-size: large;">Texas A&amp;M University</b><br>
            <b style="font-size: large;">B.S. Computer Science</b><br>
            College Station, TX<br>
            2017-2022
        </td>
        <td style="white-space: pre-wrap; vertical-align: top; font-size: medium;">(2017-2021) <b>President's Endowed Scholarship</b><br>(2018) Bertha &amp; Samuel Martin Scholarship<br>(Oct-Dec 2018) STEM and Stars Research Participant in the College of Education </td>
  </tr> 
</table>
</div>
</div>

<div class="service">
  <h2 id="service_id">Service</h2>
  <div class="table-responsive-sm">
  <table class="table table-borderless table-sm"> 
  <tr><td style="width: 35%; vertical-align: top;"><b style="font-size: large;">Reviewer</b><br></td>
    <td style="white-space: pre-wrap; vertical-align: top; font-size: medium;"><a href="https://aclrollingreview.org/"><b>ACL ARR</b>: Aug 2024</a><br><a href="https://www.icwsm.org/2024/index.html/"><b>ICWSM</b>: Jan 2024, May 2024, Sep 2024</td>
  </tr> 
  </table>
  </div>
  </div>

<div class="work">
<h2 id="work_id">Work</h2>
<div class="table-responsive-sm">
<table class="table table-borderless table-sm"> 

<tr>
<td style="width: 35%; vertical-align: top;">
    <b style="font-size: large;">RetailMeNot</b><br>
    <b style="font-size: large;">Software Engineering Intern</b><br>
    Austin, TX<br>
    May 2021 - August 2021
</td>

<td style="white-space: pre-wrap; vertical-align: top; font-size: medium;">Used Amazon SageMaker and spaCy to get BERT embeddings for concatenated coupon titles and descriptions. <b>Analyzed the relationship between each dimension of the BERT embeddings and uCTR</b> using Spearman's correlation coefficient, and used principal component analysis to find dimensions with stronger correlations. Created a plan to evaluate these dimensions as possible features for the Ranker algorithm--which does store page coupon ranking--using offline analysis and A/B testing. Taught Data Science Guilds about neural networks, word embeddings, and spaCy.</td>
</tr> 

<tr>
<td style="width: 35%; vertical-align: top;">
    <b style="font-size: large;">The Hi, How Are You Project</b><br>
    <b style="font-size: large;">Volunteer</b><br>
    Austin, TX<br>
    May 2020 - Dec 2020
</td>

<td style="white-space: pre-wrap; vertical-align: top; font-size: medium;"><b>Developed the “Friendly Frog” Alexa Skill</b> with the organization at the beginning of the COVID-19 pandemic to promote mental health by reading uplifting Daniel Johnston lyrics and the organization’s “Happy Habits.”</td>
</tr> 
<tr>

<td style="width: 35%; vertical-align: top;">
    <b style="font-size: large;">RetailMeNot</b><br>
    <b style="font-size: large;">Software Engineering Intern</b><br>
    Austin, TX<br>
    May 2020 - August 2020
</td>

<td style="white-space: pre-wrap; vertical-align: top; font-size: medium;"><b>Developed the “RetailMeNot DealFinder” Alexa Skill</b> to help users activate cash back offers. Presented on Alexa Skill Development at the Data Science Sandbox with both Valassis and RetailMeNot teams.</td>
</tr> 

<tr>
<td style="width: 35%; vertical-align: top;">
    <b style="font-size: large;">Silicon Labs</b><br>
    <b style="font-size: large;">Applications Engineering Intern</b><br>
    Austin, TX<br>
    May 2019 - August 2019
</td>
<td style="white-space: pre-wrap; vertical-align: top; font-size: medium;"><b>Designed and implemented the Snooper library</b> using pandas to (1) systemize IC bus traffic snooping (I2C, UART, SPI, etc.) across different snooping devices (Saleae, Beagle, etc.), and (2) translate the traffic to a human-readable form for debugging purposes. Responded to multiple tickets from customers using the library.</td>
</tr> 

</table>
</div>
</div>

<div class="teaching">

<h2 id="teaching_id">Teaching</h2>
<div class="table-responsive-sm">
<table class="table table-borderless table-sm"> 

<tr>
<td style="width: 35%; vertical-align: top;">
    <b style="font-size: large;">TAMU CSCE 485</b><br>
    <b style="font-size: large;">Graduate Mentor</b><br>
    Aug 2023 - Dec 2023
</td>
<td style="white-space: pre-wrap; vertical-align: top; font-size: medium;">Mentored undergraduate student, Soohwan Kim, to work on a <b>disfluency-related research project</b> for CSCE 485 Directed Studies class.</td>
</tr> 

<tr>
<td style="width: 35%; vertical-align: top;">
    <b style="font-size: large;">TAMU CSCE 121, 181</b><br>
    <b style="font-size: large;">Peer Teacher</b><br>
    Dec 2018 - Dec 2019
</td>
<td style="white-space: pre-wrap; vertical-align: top; font-size: medium;">Helped students with programming homework and answered conceptual questions by hosting office hours and <b>assisting at lab sessions for CSCE 121 and 181</b>. Created notes with exercises and examples to work through as a group during CSCE 121 reviews.</td>

</tr> 
<tr>
<td style="width: 35%; vertical-align: top;">
    <b style="font-size: large;">The Y (YMCA)</b><br>
    <b style="font-size: large;">Afterschool Instructor</b><br>
    Sep 2016 - July 2017
</td>
<td style="white-space: pre-wrap; vertical-align: top; font-size: medium;"><b>Taught multiple weekly classes</b> at local elementary schools for the YMCA Afterschool program, and <b>authored instruction manuals</b> (Lego Mindstorms Robotics and Crazy Science) for the program.</td>
</tr> 

<tr>
<td style="width: 35%; vertical-align: top;">
    <b style="font-size: large;">The Y (YMCA)</b><br>
    <b style="font-size: large;">Camp Counselor &amp; Robotics Instructor</b><br>
    May 2016 - Aug 2016
</td>
<td style="white-space: pre-wrap; vertical-align: top; font-size: medium;">Tenderfoot (K-1st) summer camp counselor in the mornings, and Lego Mindstorms <b>robotics instructor</b> in the afternoons: designed curriculum, created competition, helped kids engage in the Engineering Process, and worked with them on how to problem-solve in a group setting.</td>
</tr> 

</table>
</div>
</div>

<div class="more">
<h2 id="more_id">More</h2>
<div class="table-responsive-sm">
<table class="table table-borderless table-sm"> 

<tr>
  <td style="width: 35%; vertical-align: top;"><b style="font-size: large;">Talks</b><br></td>
  <td style="white-space: pre-wrap; vertical-align: top; font-size: medium;">(Fall 2024) <i><a href="./pdf/The Other AI.pdf">The Other AI: An Intuitive Understanding of Artificial Intelligence</a></i> @ <a href="https://vbma.biz">Texas Tech University - School of Veterinary Medicine VBMA Club</a>.</td>
</tr>

<tr>
  <td style="width: 35%; vertical-align: top;"><b style="font-size: large;">Certifications</b><br></td>
  <td style="white-space: pre-wrap; vertical-align: top; font-size: medium;">(Spring 2023) <a href="https://grad.tamu.edu/professional-development/grad-aggies">G.R.A.D. Aggies</a> Basic Professional Development Certificate</td>
</tr> 

<tr>
  <td style="width: 35%; vertical-align: top;"><b style="font-size: large;">Relevant Coursework</b><br></td>
  <td style="white-space: pre-wrap; vertical-align: top; font-size: medium;">CSCE 689 Large Language Models<br>CSCE 670 Information Storage &amp; Retrieval<br>CSCE 625 Artificial Intelligence<br>CSCE 489 Recommender Systems<br>CSCE 421 Machine Learning<br>CSCE 435/735 Parallel Computing<br>ECEN 314 Signals and Systems<br>MATH 411 Mathematical Probability<br>MATH 308 Differential Equations<br>MATH 311 Topics in Applied Math I (Linear Algebra)<br>PHIL 482 Ethics and Engineering
</td>
</tr> 
</table>
</div>
</div>


</article>
</div>
</div>

<!-- Footer -->    
<footer class="fixed-bottom bg-dark text-white">
<div class="container mt-0">© Copyright 2024 Maria  Teleki. Based on <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener noopener noreferrer" target="_blank">al-folio</a> theme. <a href="https://github.com/mariateleki/mariateleki.github.io" rel="external nofollow noopener noopener noreferrer" target="_blank">Code available at my GitHub.</a></div>
</footer>

<!-- JavaScripts -->
<!-- jQuery -->
<!-- <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>-->
<script src="./assets/jquery/dist/jquery.min.js"></script>

<!-- Bootsrap & MDB scripts -->
<!-- <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> -->
<script src="./assets/bootstrap-4.6.1-dist/js/bootstrap.bundle.min.js"></script> 

<!-- <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> -->
<script src="./assets/MDB-Free_4.20.0/js/mdb.min.js"></script>

</body>
</html>

